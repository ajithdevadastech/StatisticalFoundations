{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "275e911d",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis¶\n",
    "Demo 1: Detecting and Removing Outliers\n",
    "In this demo, you will be shown how to detect and remove outliers using Z-score and IQR score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ef41017",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step1: Import the required libraries\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from scipy import stats\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "851db8e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "\n`load_boston` has been removed from scikit-learn since version 1.2.\n\nThe Boston housing prices dataset has an ethical problem: as\ninvestigated in [1], the authors of this dataset engineered a\nnon-invertible variable \"B\" assuming that racial self-segregation had a\npositive impact on house prices [2]. Furthermore the goal of the\nresearch that led to the creation of this dataset was to study the\nimpact of air quality but it did not give adequate demonstration of the\nvalidity of this assumption.\n\nThe scikit-learn maintainers therefore strongly discourage the use of\nthis dataset unless the purpose of the code is to study and educate\nabout ethical issues in data science and machine learning.\n\nIn this special case, you can fetch the dataset from the original\nsource::\n\n    import pandas as pd\n    import numpy as np\n\n    data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n    raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n    data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n    target = raw_df.values[1::2, 2]\n\nAlternative datasets include the California housing dataset and the\nAmes housing dataset. You can load the datasets as follows::\n\n    from sklearn.datasets import fetch_california_housing\n    housing = fetch_california_housing()\n\nfor the California housing dataset and::\n\n    from sklearn.datasets import fetch_openml\n    housing = fetch_openml(name=\"house_prices\", as_frame=True)\n\nfor the Ames housing dataset.\n\n[1] M Carlisle.\n\"Racist data destruction?\"\n<https://medium.com/@docintangible/racist-data-destruction-113e3eff54a8>\n\n[2] Harrison Jr, David, and Daniel L. Rubinfeld.\n\"Hedonic housing prices and the demand for clean air.\"\nJournal of environmental economics and management 5.1 (1978): 81-102.\n<https://www.researchgate.net/publication/4974606_Hedonic_housing_prices_and_the_demand_for_clean_air>\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Step2: Load the Boston House Pricing Dataset which is included in the sklearn dataset API\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_boston\n\u001b[0;32m      3\u001b[0m boston \u001b[38;5;241m=\u001b[39m load_boston()\n\u001b[0;32m      4\u001b[0m x \u001b[38;5;241m=\u001b[39m boston\u001b[38;5;241m.\u001b[39mdata\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\datasets\\__init__.py:157\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mload_boston\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    109\u001b[0m     msg \u001b[38;5;241m=\u001b[39m textwrap\u001b[38;5;241m.\u001b[39mdedent(\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;124m        `load_boston` has been removed from scikit-learn since version 1.2.\u001b[39m\n\u001b[0;32m    111\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;124m        <https://www.researchgate.net/publication/4974606_Hedonic_housing_prices_and_the_demand_for_clean_air>\u001b[39m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;124m        \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m)\n\u001b[1;32m--> 157\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mglobals\u001b[39m()[name]\n",
      "\u001b[1;31mImportError\u001b[0m: \n`load_boston` has been removed from scikit-learn since version 1.2.\n\nThe Boston housing prices dataset has an ethical problem: as\ninvestigated in [1], the authors of this dataset engineered a\nnon-invertible variable \"B\" assuming that racial self-segregation had a\npositive impact on house prices [2]. Furthermore the goal of the\nresearch that led to the creation of this dataset was to study the\nimpact of air quality but it did not give adequate demonstration of the\nvalidity of this assumption.\n\nThe scikit-learn maintainers therefore strongly discourage the use of\nthis dataset unless the purpose of the code is to study and educate\nabout ethical issues in data science and machine learning.\n\nIn this special case, you can fetch the dataset from the original\nsource::\n\n    import pandas as pd\n    import numpy as np\n\n    data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n    raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n    data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n    target = raw_df.values[1::2, 2]\n\nAlternative datasets include the California housing dataset and the\nAmes housing dataset. You can load the datasets as follows::\n\n    from sklearn.datasets import fetch_california_housing\n    housing = fetch_california_housing()\n\nfor the California housing dataset and::\n\n    from sklearn.datasets import fetch_openml\n    housing = fetch_openml(name=\"house_prices\", as_frame=True)\n\nfor the Ames housing dataset.\n\n[1] M Carlisle.\n\"Racist data destruction?\"\n<https://medium.com/@docintangible/racist-data-destruction-113e3eff54a8>\n\n[2] Harrison Jr, David, and Daniel L. Rubinfeld.\n\"Hedonic housing prices and the demand for clean air.\"\nJournal of environmental economics and management 5.1 (1978): 81-102.\n<https://www.researchgate.net/publication/4974606_Hedonic_housing_prices_and_the_demand_for_clean_air>\n"
     ]
    }
   ],
   "source": [
    "#Step2: Load the Boston House Pricing Dataset which is included in the sklearn dataset API\n",
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "x = boston.data\n",
    "y = boston.target\n",
    "columns = boston.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "341640c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.00</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>396.90000</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>396.90000</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>396.90000</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>393.45000</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>396.90000</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1012 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0      1      2    3      4      5     6       7    8      9   \\\n",
       "0       0.00632  18.00   2.31  0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1     396.90000   4.98  24.00  NaN    NaN    NaN   NaN     NaN  NaN    NaN   \n",
       "2       0.02731   0.00   7.07  0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "3     396.90000   9.14  21.60  NaN    NaN    NaN   NaN     NaN  NaN    NaN   \n",
       "4       0.02729   0.00   7.07  0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "...         ...    ...    ...  ...    ...    ...   ...     ...  ...    ...   \n",
       "1007  396.90000   5.64  23.90  NaN    NaN    NaN   NaN     NaN  NaN    NaN   \n",
       "1008    0.10959   0.00  11.93  0.0  0.573  6.794  89.3  2.3889  1.0  273.0   \n",
       "1009  393.45000   6.48  22.00  NaN    NaN    NaN   NaN     NaN  NaN    NaN   \n",
       "1010    0.04741   0.00  11.93  0.0  0.573  6.030  80.8  2.5050  1.0  273.0   \n",
       "1011  396.90000   7.88  11.90  NaN    NaN    NaN   NaN     NaN  NaN    NaN   \n",
       "\n",
       "        10  \n",
       "0     15.3  \n",
       "1      NaN  \n",
       "2     17.8  \n",
       "3      NaN  \n",
       "4     17.8  \n",
       "...    ...  \n",
       "1007   NaN  \n",
       "1008  21.0  \n",
       "1009   NaN  \n",
       "1010  21.0  \n",
       "1011   NaN  \n",
       "\n",
       "[1012 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
    "boston = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
    "x = np.hstack([boston.values[::2, :], boston.values[1::2, :2]])\n",
    "y = boston.values[1::2, 2]\n",
    "\n",
    "boston\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9851871",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.00</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>396.90000</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>396.90000</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM     ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0    0.00632  18.00   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  396.90000   4.98  24.00   0.0  0.000  0.000   0.0  0.0000  0.0    0.0   \n",
       "2    0.02731   0.00   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "3  396.90000   9.14  21.60   0.0  0.000  0.000   0.0  0.0000  0.0    0.0   \n",
       "4    0.02729   0.00   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "\n",
       "   PTRATIO  \n",
       "0     15.3  \n",
       "1      0.0  \n",
       "2     17.8  \n",
       "3      0.0  \n",
       "4     17.8  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Step3: Create the dataframe\n",
    "boston_df = pd.DataFrame(boston)\n",
    "boston_df.columns = ['CRIM','ZN','INDUS','CHAS','NOX','RM','AGE','DIS','RAD','TAX','PTRATIO']\n",
    "boston_df = boston_df.fillna(value=0)\n",
    "boston_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59168302",
   "metadata": {},
   "source": [
    "# Using Z-Score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "035210e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          CRIM        ZN     INDUS      CHAS       NOX        RM       AGE  \\\n",
      "0     0.957975  0.347499  1.466008  0.189272  0.901366  1.079028  0.779908   \n",
      "1     1.152714  0.407625  0.723195  0.189272  0.959099  0.987754  0.865055   \n",
      "2     0.957863  0.696451  0.985574  0.189272  0.662756  1.030619  1.125552   \n",
      "3     1.152714  0.166356  0.480959  0.189272  0.959099  0.987754  0.865055   \n",
      "4     0.957863  0.696451  0.985574  0.189272  0.662756  1.270775  0.676467   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "1007  1.152714  0.369347  0.713101  0.189272  0.959099  0.987754  0.865055   \n",
      "1008  0.957426  0.696451  0.495048  0.189272  1.022400  1.147868  1.387938   \n",
      "1009  1.134367  0.320629  0.521332  0.189272  0.959099  0.987754  0.865055   \n",
      "1010  0.957756  0.696451  0.495048  0.189272  1.022400  0.907713  1.173488   \n",
      "1011  1.152714  0.239433  0.498076  0.189272  0.959099  0.987754  0.865055   \n",
      "\n",
      "           DIS       RAD       TAX   PTRATIO  \n",
      "0     0.909342  0.484769  0.388830  0.649184  \n",
      "1     0.787007  0.613195  0.863803  0.986543  \n",
      "2     1.273124  0.356344  0.160309  0.916460  \n",
      "3     0.787007  0.613195  0.863803  0.986543  \n",
      "4     1.273124  0.356344  0.160309  0.916460  \n",
      "...        ...       ...       ...       ...  \n",
      "1007  0.787007  0.613195  0.863803  0.986543  \n",
      "1008  0.203802  0.484769  0.291497  1.258573  \n",
      "1009  0.787007  0.613195  0.863803  0.986543  \n",
      "1010  0.251955  0.484769  0.291497  1.258573  \n",
      "1011  0.787007  0.613195  0.863803  0.986543  \n",
      "\n",
      "[1012 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "#Step1: Use Z-score function defined in scipy library to detect the outliers\n",
    "boston_df_z = boston_df\n",
    "z = np.abs(stats.zscore(boston_df))\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13b7500",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looking at the code and the output above, it is difficult to say which data point is an outlier. So let’s define a threshold to identify an outlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1aa5230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 78,  80, 108, 110, 112, 112, 114, 128, 130, 132, 284, 304, 308,\n",
      "       310, 320, 323, 324, 325, 326, 327, 333, 373, 390, 391, 392, 394,\n",
      "       396, 398, 400, 402, 404, 406, 407, 408, 409, 416, 418, 420, 422,\n",
      "       424, 432, 436, 438, 440, 442, 444, 451, 457, 467, 468, 472, 508,\n",
      "       508, 510, 510, 512, 515, 525, 535, 538, 546, 548, 552, 554, 564,\n",
      "       566, 566, 567, 568, 572, 580, 582, 584, 596, 598, 600, 694, 696,\n",
      "       702, 704, 706, 706, 708, 708, 710, 710, 712, 714, 716, 726, 728,\n",
      "       737, 738, 739, 740, 741, 743, 744, 745], dtype=int64), array([1, 1, 1, 1, 1, 7, 1, 7, 1, 1, 3, 3, 3, 3, 3, 2, 3, 2, 3, 2, 2, 2,\n",
      "       1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "       3, 3, 2, 2, 2, 3, 3, 1, 7, 1, 7, 1, 2, 2, 2, 3, 3, 3, 3, 3, 3, 1,\n",
      "       3, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 1, 7, 1, 7, 1, 7, 3, 3,\n",
      "       3, 3, 3, 2, 3, 2, 3, 2, 2, 3, 2], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "#Step2: Define a threshold\n",
    "threshold = 3\n",
    "print(np.where(z > threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0db975",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The first array contains the list of row numbers and second array contains the respective column numbers, which means that z[55][1] has a z-score higher than 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14830382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The no. of rows before outlier filtering was:  (1012, 11)\n",
      "The no. of rows after outlier filtering is:  (920, 11)\n"
     ]
    }
   ],
   "source": [
    "#Step3: Remove the outliers using the z-score\n",
    "boston_df_z = boston_df_z[(z < threshold).all(axis=1)]\n",
    "\n",
    "print(\"The no. of rows before outlier filtering was: \", boston_df.shape)\n",
    "print(\"The no. of rows after outlier filtering is: \", boston_df_z.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12788006",
   "metadata": {},
   "source": [
    "# Using IQR Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c186f9f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRIM       391.177170\n",
      "ZN          16.780000\n",
      "INDUS       13.515000\n",
      "CHAS         0.000000\n",
      "NOX          0.538000\n",
      "RM           6.208250\n",
      "AGE         77.400000\n",
      "DIS          3.203325\n",
      "RAD          5.000000\n",
      "TAX        330.000000\n",
      "PTRATIO     19.025000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Step1: Calculate the IQR\n",
    "boston_df_iqr = boston_df\n",
    "Q1 = boston_df_iqr.quantile(0.25)\n",
    "Q3 = boston_df_iqr.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "print(IQR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90252f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       CRIM     ZN  INDUS   CHAS    NOX     RM    AGE    DIS    RAD    TAX  \\\n",
      "0     False  False  False  False  False  False  False  False  False  False   \n",
      "1     False  False  False  False  False  False  False  False  False  False   \n",
      "2     False  False  False  False  False  False  False  False  False  False   \n",
      "3     False  False  False  False  False  False  False  False  False  False   \n",
      "4     False  False  False  False  False  False  False  False  False  False   \n",
      "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "1007  False  False  False  False  False  False  False  False  False  False   \n",
      "1008  False  False  False  False  False  False  False  False  False  False   \n",
      "1009  False  False  False  False  False  False  False  False  False  False   \n",
      "1010  False  False  False  False  False  False  False  False  False  False   \n",
      "1011  False  False  False  False  False  False  False  False  False  False   \n",
      "\n",
      "      PTRATIO  \n",
      "0       False  \n",
      "1       False  \n",
      "2       False  \n",
      "3       False  \n",
      "4       False  \n",
      "...       ...  \n",
      "1007    False  \n",
      "1008    False  \n",
      "1009    False  \n",
      "1010    False  \n",
      "1011    False  \n",
      "\n",
      "[1012 rows x 11 columns]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot perform 'ror_' with a dtyped [bool] array and scalar of type [NoneType]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:311\u001b[0m, in \u001b[0;36mna_logical_op\u001b[1;34m(x, y, op)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    303\u001b[0m     \u001b[38;5;66;03m# For exposition, write:\u001b[39;00m\n\u001b[0;32m    304\u001b[0m     \u001b[38;5;66;03m#  yarr = isinstance(y, np.ndarray)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    309\u001b[0m     \u001b[38;5;66;03m# Then Cases where this goes through without raising include:\u001b[39;00m\n\u001b[0;32m    310\u001b[0m     \u001b[38;5;66;03m#  (xint or xbool) and (yint or bool)\u001b[39;00m\n\u001b[1;32m--> 311\u001b[0m     result \u001b[38;5;241m=\u001b[39m op(x, y)\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\roperator.py:58\u001b[0m, in \u001b[0;36mror_\u001b[1;34m(left, right)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mror_\u001b[39m(left, right):\n\u001b[1;32m---> 58\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m operator\u001b[38;5;241m.\u001b[39mor_(right, left)\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for |: 'NoneType' and 'bool'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:325\u001b[0m, in \u001b[0;36mna_logical_op\u001b[1;34m(x, y, op)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 325\u001b[0m     result \u001b[38;5;241m=\u001b[39m libops\u001b[38;5;241m.\u001b[39mscalar_binop(x, y, op)\n\u001b[0;32m    326\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\n\u001b[0;32m    327\u001b[0m     \u001b[38;5;167;01mTypeError\u001b[39;00m,\n\u001b[0;32m    328\u001b[0m     \u001b[38;5;167;01mValueError\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    331\u001b[0m     \u001b[38;5;167;01mNotImplementedError\u001b[39;00m,\n\u001b[0;32m    332\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\ops.pyx:180\u001b[0m, in \u001b[0;36mpandas._libs.ops.scalar_binop\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Buffer has wrong number of dimensions (expected 1, got 2)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Step2: Detect the outliers\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(boston_df_iqr \u001b[38;5;241m<\u001b[39m (Q1 \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1.5\u001b[39m \u001b[38;5;241m*\u001b[39m IQR)) \u001b[38;5;241m|\u001b[39m(boston_df_iqr \u001b[38;5;241m>\u001b[39m (Q3 \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1.5\u001b[39m \u001b[38;5;241m*\u001b[39m IQR))\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\ops\\common.py:81\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m     79\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[1;32m---> 81\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m method(\u001b[38;5;28mself\u001b[39m, other)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\arraylike.py:82\u001b[0m, in \u001b[0;36mOpsMixin.__ror__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__ror__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__ror__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m---> 82\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logical_method(other, roperator\u001b[38;5;241m.\u001b[39mror_)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:7457\u001b[0m, in \u001b[0;36mDataFrame._arith_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   7453\u001b[0m other \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mmaybe_prepare_scalar_for_op(other, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape[axis],))\n\u001b[0;32m   7455\u001b[0m \u001b[38;5;28mself\u001b[39m, other \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39malign_method_FRAME(\u001b[38;5;28mself\u001b[39m, other, axis, flex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, level\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m-> 7457\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch_frame_op(other, op, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[0;32m   7458\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(new_data)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:7484\u001b[0m, in \u001b[0;36mDataFrame._dispatch_frame_op\u001b[1;34m(self, right, func, axis)\u001b[0m\n\u001b[0;32m   7481\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_list_like(right):\n\u001b[0;32m   7482\u001b[0m     \u001b[38;5;66;03m# i.e. scalar, faster than checking np.ndim(right) == 0\u001b[39;00m\n\u001b[0;32m   7483\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 7484\u001b[0m         bm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mapply(array_op, right\u001b[38;5;241m=\u001b[39mright)\n\u001b[0;32m   7485\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor(bm)\n\u001b[0;32m   7487\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(right, DataFrame):\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:350\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    347\u001b[0m             kwargs[k] \u001b[38;5;241m=\u001b[39m obj[b\u001b[38;5;241m.\u001b[39mmgr_locs\u001b[38;5;241m.\u001b[39mindexer]\n\u001b[0;32m    349\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(f):\n\u001b[1;32m--> 350\u001b[0m     applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    352\u001b[0m     applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(b, f)(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:329\u001b[0m, in \u001b[0;36mBlock.apply\u001b[1;34m(self, func, **kwargs)\u001b[0m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Block]:\n\u001b[0;32m    325\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    326\u001b[0m \u001b[38;5;124;03m    apply the function to my values; return a block if we are not\u001b[39;00m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;124;03m    one\u001b[39;00m\n\u001b[0;32m    328\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 329\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    331\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split_op_result(result)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:401\u001b[0m, in \u001b[0;36mlogical_op\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m    397\u001b[0m \u001b[38;5;66;03m# For int vs int `^`, `|`, `&` are bitwise operators and return\u001b[39;00m\n\u001b[0;32m    398\u001b[0m \u001b[38;5;66;03m#   integer dtypes.  Otherwise these are boolean ops\u001b[39;00m\n\u001b[0;32m    399\u001b[0m filler \u001b[38;5;241m=\u001b[39m fill_int \u001b[38;5;28;01mif\u001b[39;00m is_self_int_dtype \u001b[38;5;129;01mand\u001b[39;00m is_other_int_dtype \u001b[38;5;28;01melse\u001b[39;00m fill_bool\n\u001b[1;32m--> 401\u001b[0m res_values \u001b[38;5;241m=\u001b[39m na_logical_op(lvalues, rvalues, op)\n\u001b[0;32m    402\u001b[0m \u001b[38;5;66;03m# error: Cannot call function of unknown type\u001b[39;00m\n\u001b[0;32m    403\u001b[0m res_values \u001b[38;5;241m=\u001b[39m filler(res_values)  \u001b[38;5;66;03m# type: ignore[operator]\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:334\u001b[0m, in \u001b[0;36mna_logical_op\u001b[1;34m(x, y, op)\u001b[0m\n\u001b[0;32m    326\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m (\n\u001b[0;32m    327\u001b[0m             \u001b[38;5;167;01mTypeError\u001b[39;00m,\n\u001b[0;32m    328\u001b[0m             \u001b[38;5;167;01mValueError\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    331\u001b[0m             \u001b[38;5;167;01mNotImplementedError\u001b[39;00m,\n\u001b[0;32m    332\u001b[0m         ) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    333\u001b[0m             typ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(y)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[1;32m--> 334\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    335\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot perform \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mop\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m with a dtyped [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] array \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    336\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand scalar of type [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtyp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    337\u001b[0m             ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m    339\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mreshape(x\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[1;31mTypeError\u001b[0m: Cannot perform 'ror_' with a dtyped [bool] array and scalar of type [NoneType]"
     ]
    }
   ],
   "source": [
    "#Step2: Detect the outliers\n",
    "print(boston_df_iqr < (Q1 - 1.5 * IQR)) |(boston_df_iqr > (Q3 + 1.5 * IQR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9211d53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The data point where we have False means that these values are valid whereas True indicates presence of an outlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c40e3e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The no. of rows before outlier filtering was:  (1012, 11)\n",
      "The no. of rows after outlier filtering is:  (765, 11)\n"
     ]
    }
   ],
   "source": [
    "#Step3: Remove the outliers using the IQR score\n",
    "boston_df_out = boston_df_iqr[~((boston_df_iqr < (Q1 - 1.5 * IQR)) |(boston_df_iqr > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "\n",
    "print(\"The no. of rows before outlier filtering was: \", boston_df_iqr.shape)\n",
    "print(\"The no. of rows after outlier filtering is: \", boston_df_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "02271c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hence, the outliers have been removed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
